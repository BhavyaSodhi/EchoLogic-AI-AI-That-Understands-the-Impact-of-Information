{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e63d19b987d4a86b873d275beb240e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ee6ecaae2dc4336af16a7c368018b3a",
              "IPY_MODEL_5d63e5daa8c34c8eb74772e16dd093cd",
              "IPY_MODEL_c5d0429c3a984839990a456441cc2132"
            ],
            "layout": "IPY_MODEL_54d322f12f7b4b3f91b123a36e5bc9a7"
          }
        },
        "9ee6ecaae2dc4336af16a7c368018b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_622ae706e4df43c6a4c976804fcc674c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3563892f359c4a64b6927042d0d2da22",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "5d63e5daa8c34c8eb74772e16dd093cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f22da30a46143f5bc37b7583cebf11f",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_034d563a6d3b41858cbe780afa9d4332",
            "value": 103
          }
        },
        "c5d0429c3a984839990a456441cc2132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b275f57a68b4ce39dac45e867850fc0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9d71c246d7704f3d8a0ab7ffb41cee84",
            "value": "‚Äá103/103‚Äá[00:00&lt;00:00,‚Äá435.82it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "54d322f12f7b4b3f91b123a36e5bc9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622ae706e4df43c6a4c976804fcc674c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3563892f359c4a64b6927042d0d2da22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f22da30a46143f5bc37b7583cebf11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034d563a6d3b41858cbe780afa9d4332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b275f57a68b4ce39dac45e867850fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d71c246d7704f3d8a0ab7ffb41cee84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40cb098e504045479f85f0cb3ab67115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c5eb5ca02384ab8b45c7d7d019b2ad8",
              "IPY_MODEL_32d87e741e8e41ceb321ae2935fc8ae6",
              "IPY_MODEL_53414d685b6e424faa76e565482f3e19"
            ],
            "layout": "IPY_MODEL_be5b8ce39a7e4a47a4092d368053b358"
          }
        },
        "4c5eb5ca02384ab8b45c7d7d019b2ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af73973650145ec910b4fe79199c5ea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aab15832f3d04519a327fea2a96dadc9",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "32d87e741e8e41ceb321ae2935fc8ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6730e9c94bc428196282ee89b13ffa5",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f89705385d98453b8fa440c7861a8767",
            "value": 103
          }
        },
        "53414d685b6e424faa76e565482f3e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f62284946084d6399dad8da6b7f7012",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_06022b5dc47d40d99081358fc2bfe663",
            "value": "‚Äá103/103‚Äá[00:00&lt;00:00,‚Äá125.59it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "be5b8ce39a7e4a47a4092d368053b358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af73973650145ec910b4fe79199c5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab15832f3d04519a327fea2a96dadc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6730e9c94bc428196282ee89b13ffa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89705385d98453b8fa440c7861a8767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f62284946084d6399dad8da6b7f7012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06022b5dc47d40d99081358fc2bfe663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EchoLogic AI ‚Äì ‚ÄúAI That Understands the Impact of Information‚Äù**\n",
        "One-Line Idea (Very Simple)\n",
        "\n",
        "EchoLogic AI predicts how long any information (post, news, idea, video) will stay alive on the internet and when people will stop caring about it.\n",
        "\n",
        "No emotions.\n",
        "No medical stuff.\n",
        "No past dataset.\n",
        "No selection system.\n",
        "\n",
        "üß© Combined Ideas (3-in-1)\n",
        "\n",
        "This project combines THREE ideas that are never merged together:\n",
        "\n",
        "Information Lifespan Prediction\n",
        "\n",
        "Attention Decay Modeling\n",
        "\n",
        "Competition Pressure Analysis\n",
        "\n",
        "üëâ These are NOT present together in today‚Äôs consumer AI systems.\n",
        "\n",
        "üß† What Problem Does It Solve?\n",
        "\n",
        "In real life:\n",
        "\n",
        "Some news explodes and dies in 1 day\n",
        "\n",
        "Some posts live for weeks\n",
        "\n",
        "Some ideas never take off\n",
        "\n",
        "But nobody knows WHY or HOW LONG it will last\n",
        "\n",
        "üëâ EchoLogic AI answers:\n",
        "\n",
        "‚ÄúHow long will this content survive?‚Äù\n",
        "\n",
        "‚ÄúWhen will people stop paying attention?‚Äù\n",
        "\n",
        "‚ÄúIs it worth posting this now?‚Äù\n"
      ],
      "metadata": {
        "id": "8trvGj3xI59g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio numpy plotly reportlab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcgywNVGDcWl",
        "outputId": "fd8190ca-d1d3-4112-8b6d-e6268cfc1d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.9)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.3.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "qPEuI47yHeml",
        "outputId": "a163ff10-8b4e-4f26-b318-e17902aff1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1567274588.py:222: DeprecationWarning:\n",
            "\n",
            "The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://06aece9db6577729b8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://06aece9db6577729b8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚ÄúUrbanFlow AI‚Äù ‚Äì Real-Time City Pulse Simulator**"
      ],
      "metadata": {
        "id": "XdhcgQUHR-QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# UrbanFlow AI v7\n",
        "# Hackathon-Level Smart City Simulator with AI Resource Allocation\n",
        "# ==========================================================\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "import random, hashlib\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.pagesizes import A4\n",
        "import tempfile\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# CITY FLOW & RESOURCE SIMULATION\n",
        "# ----------------------------------------------------------\n",
        "def simulate_city_flow(event_type, time_of_day, weather, steps, energy_limit, water_limit, sanitation_limit):\n",
        "    base_people = {\"Concert\":3000,\"Football Match\":5000,\"Market\":1500,\"Festival\":4000,\"General\":1000}\n",
        "    base_vehicle = {\"Concert\":800,\"Football Match\":1200,\"Market\":400,\"Festival\":1000,\"General\":300}\n",
        "    base_energy = {\"Concert\":50,\"Football Match\":80,\"Market\":20,\"Festival\":60,\"General\":10}\n",
        "    base_water = {\"Concert\":30,\"Football Match\":50,\"Market\":10,\"Festival\":40,\"General\":5}\n",
        "    base_sanitation = {\"Concert\":20,\"Football Match\":30,\"Market\":10,\"Festival\":25,\"General\":5}\n",
        "\n",
        "    time_mod = {\"Morning\":0.8,\"Afternoon\":1.0,\"Evening\":1.2,\"Night\":0.6}\n",
        "    weather_mod = {\"Sunny\":1.0,\"Rainy\":0.7,\"Windy\":0.85}\n",
        "\n",
        "    people, traffic, energy, water, sanitation = [], [], [], [], []\n",
        "\n",
        "    for t in range(steps):\n",
        "        fluct = random.uniform(0.8,1.2)\n",
        "        p = base_people.get(event_type,1000) * time_mod.get(time_of_day,1.0) * weather_mod.get(weather,1.0) * fluct\n",
        "        v = base_vehicle.get(event_type,300) * time_mod.get(time_of_day,1.0) * weather_mod.get(weather,1.0) * fluct\n",
        "        e = min(base_energy.get(event_type,10) * fluct, energy_limit)\n",
        "        w = min(base_water.get(event_type,5) * fluct, water_limit)\n",
        "        s = min(base_sanitation.get(event_type,5) * fluct, sanitation_limit)\n",
        "        people.append(p)\n",
        "        traffic.append(v)\n",
        "        energy.append(e)\n",
        "        water.append(w)\n",
        "        sanitation.append(s)\n",
        "\n",
        "    return np.array(people), np.array(traffic), np.array(energy), np.array(water), np.array(sanitation)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# FEATURE EXTRACTION\n",
        "# ----------------------------------------------------------\n",
        "def extract_city_features(people, traffic, energy, water, sanitation):\n",
        "    f = {}\n",
        "    f[\"Avg Crowd\"] = np.mean(people)\n",
        "    f[\"Max Crowd\"] = np.max(people)\n",
        "    f[\"Min Crowd\"] = np.min(people)\n",
        "    f[\"Crowd Std\"] = np.std(people)\n",
        "    f[\"Crowd Variance\"] = np.var(people)\n",
        "    f[\"Peak Hour\"] = int(np.argmax(people))\n",
        "    f[\"Crowd Acceleration\"] = np.mean(np.diff(people))\n",
        "    f[\"Crowd Trend Volatility\"] = np.std(np.diff(people))\n",
        "    f[\"Crowd Revival Detected\"] = int(np.any(people[int(len(people)*0.6):] > np.mean(people[:int(len(people)*0.3)])))\n",
        "\n",
        "    f[\"Avg Traffic\"] = np.mean(traffic)\n",
        "    f[\"Max Traffic\"] = np.max(traffic)\n",
        "    f[\"Traffic Std\"] = np.std(traffic)\n",
        "    f[\"Traffic Variance\"] = np.var(traffic)\n",
        "    f[\"Traffic Peak\"] = int(np.argmax(traffic))\n",
        "    f[\"Traffic Trend Volatility\"] = np.std(np.diff(traffic))\n",
        "\n",
        "    f[\"Avg Energy Usage\"] = np.mean(energy)\n",
        "    f[\"Max Energy Usage\"] = np.max(energy)\n",
        "    f[\"Avg Water Usage\"] = np.mean(water)\n",
        "    f[\"Max Water Usage\"] = np.max(water)\n",
        "    f[\"Avg Sanitation Load\"] = np.mean(sanitation)\n",
        "    f[\"Max Sanitation Load\"] = np.max(sanitation)\n",
        "\n",
        "    f[\"Resource Stress Alert\"] = int(np.max(people)/5000 > 0.7 or np.max(traffic)/1500 > 0.7)\n",
        "    f[\"Risk Level\"] = min(1.0, np.max(people)/5000 + np.max(traffic)/1500)\n",
        "    f[\"Longevity Score\"] = np.mean(people)/1000\n",
        "    f[\"Confidence Score\"] = max(0.1, 1 - f[\"Risk Level\"])\n",
        "    f[\"Event Pulse Score\"] = f[\"Longevity Score\"] * f[\"Confidence Score\"]\n",
        "    f[\"Future Crowd T+30\"] = people[-1]*1.05\n",
        "    f[\"Future Traffic T+30\"] = traffic[-1]*1.05\n",
        "\n",
        "    # -------------------------\n",
        "    # AI Resource Recommendation\n",
        "    # -------------------------\n",
        "    f[\"Recommended Energy\"] = min(np.max(energy)*1.1, 200)\n",
        "    f[\"Recommended Water\"] = min(np.max(water)*1.1, 100)\n",
        "    f[\"Recommended Sanitation\"] = min(np.max(sanitation)*1.1, 100)\n",
        "\n",
        "    return f\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# INFORMATION DNA\n",
        "# ----------------------------------------------------------\n",
        "def information_dna(text):\n",
        "    return hashlib.sha256(text.encode()).hexdigest()[:16]\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# HUMAN-READABLE REASONING & ALERTS\n",
        "# ----------------------------------------------------------\n",
        "def reasoning_engine(f):\n",
        "    msg = []\n",
        "    msg.append(\"High risk of congestion!\" if f[\"Risk Level\"]>0.7 else \"Low congestion risk.\")\n",
        "    msg.append(\"Event is expected to be long-lasting.\" if f[\"Longevity Score\"]>2 else \"Event will fade quickly.\")\n",
        "    msg.append(\"Confidence to handle event is high.\" if f[\"Confidence Score\"]>0.7 else \"Need more planning.\")\n",
        "    msg.append(\"Trend revival detected!\" if f[\"Crowd Revival Detected\"] else \"No sudden revival detected.\")\n",
        "    msg.append(\"Resource stress alert!\" if f[\"Resource Stress Alert\"] else \"Resources sufficient.\")\n",
        "    msg.append(f\"AI Recommended Energy: {f['Recommended Energy']:.1f}\")\n",
        "    msg.append(f\"AI Recommended Water: {f['Recommended Water']:.1f}\")\n",
        "    msg.append(f\"AI Recommended Sanitation: {f['Recommended Sanitation']:.1f}\")\n",
        "    return \" \".join(msg)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# PDF REPORT\n",
        "# ----------------------------------------------------------\n",
        "def generate_pdf(features, reasoning, dna):\n",
        "    temp = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
        "    doc = SimpleDocTemplate(temp.name, pagesize=A4)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    story.append(Paragraph(\"<b>UrbanFlow AI v7 - Smart City AI Resource Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "    story.append(Paragraph(f\"Information DNA: <b>{dna}</b>\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    for k,v in features.items():\n",
        "        story.append(Paragraph(f\"{k}: {round(v,2)}\", styles[\"Normal\"]))\n",
        "\n",
        "    story.append(Spacer(1,12))\n",
        "    story.append(Paragraph(\"<b>AI Reasoning & Resource Recommendations</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Paragraph(reasoning, styles[\"Normal\"]))\n",
        "\n",
        "    doc.build(story)\n",
        "    return temp.name\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# DASHBOARD FUNCTION\n",
        "# ----------------------------------------------------------\n",
        "def urbanflow_dashboard_v7(event_type, time_of_day, weather, steps, description, energy_limit, water_limit, sanitation_limit):\n",
        "    people, traffic, energy, water, sanitation = simulate_city_flow(event_type, time_of_day, weather, steps, energy_limit, water_limit, sanitation_limit)\n",
        "    f = extract_city_features(people, traffic, energy, water, sanitation)\n",
        "    dna = information_dna(description)\n",
        "    reasoning = reasoning_engine(f)\n",
        "    pdf = generate_pdf(f, reasoning, dna)\n",
        "\n",
        "    # Animated City Map with Tooltips\n",
        "    frames = []\n",
        "    for t in range(len(people)):\n",
        "        n_people = max(1,int(people[t]//100))\n",
        "        n_vehicle = max(1,int(traffic[t]//50))\n",
        "        x_people = np.cumsum(np.random.rand(n_people)*0.5) % 10\n",
        "        y_people = np.cumsum(np.random.rand(n_people)*0.5) % 10\n",
        "        x_vehicle = np.cumsum(np.random.rand(n_vehicle)*0.7) % 10\n",
        "        y_vehicle = np.cumsum(np.random.rand(n_vehicle)*0.7) % 10\n",
        "\n",
        "        scatter_people = go.Scatter(\n",
        "            x=x_people, y=y_people, mode='markers',\n",
        "            marker=dict(size=5, color='blue'),\n",
        "            name='People',\n",
        "            hovertemplate=f'Crowd: {people[t]:.0f}<br>Risk Level: {f[\"Risk Level\"]:.2f}<extra></extra>'\n",
        "        )\n",
        "        scatter_vehicle = go.Scatter(\n",
        "            x=x_vehicle, y=y_vehicle, mode='markers',\n",
        "            marker=dict(size=7, color='red' if f[\"Risk Level\"]>0.7 else 'green'),\n",
        "            name='Vehicles',\n",
        "            hovertemplate=f'Vehicles: {traffic[t]:.0f}<br>Risk Level: {f[\"Risk Level\"]:.2f}<extra></extra>'\n",
        "        )\n",
        "\n",
        "        frames.append(go.Frame(data=[scatter_people, scatter_vehicle], name=str(t)))\n",
        "\n",
        "    g_map = go.Figure(data=[frames[0].data[0], frames[0].data[1]], frames=frames)\n",
        "    g_map.update_layout(\n",
        "        title=\"üåÜ Smart City Animated Map with AI Resource Allocation\",\n",
        "        updatemenus=[{\"type\":\"buttons\",\"buttons\":[{\"label\":\"Play\",\"method\":\"animate\",\"args\":[None]}]}],\n",
        "        xaxis=dict(range=[0,10]), yaxis=dict(range=[0,10])\n",
        "    )\n",
        "\n",
        "    # Line Charts\n",
        "    g1 = go.Figure(go.Scatter(y=people, mode=\"lines+markers\"))\n",
        "    g1.update_layout(title=\"üìà Crowd Flow Over Time\")\n",
        "    g2 = go.Figure(go.Scatter(y=traffic, mode=\"lines+markers\"))\n",
        "    g2.update_layout(title=\"üöó Traffic Flow Over Time\")\n",
        "    g3 = go.Figure(go.Heatmap(z=[people, traffic, energy], colorscale=\"Viridis\"))\n",
        "    g3.update_layout(title=\"üå° Heatmap: Crowd, Traffic, Energy\")\n",
        "    g4 = go.Figure(go.Scatterpolar(\n",
        "        r=[f[\"Avg Crowd\"], f[\"Max Crowd\"], f[\"Avg Traffic\"], f[\"Max Traffic\"], f[\"Risk Level\"]],\n",
        "        theta=[\"Avg Crowd\",\"Max Crowd\",\"Avg Traffic\",\"Max Traffic\",\"Risk\"],\n",
        "        fill=\"toself\"\n",
        "    ))\n",
        "    g4.update_layout(title=\"üï∏ Event Health Radar\")\n",
        "\n",
        "    summary = \"\\n\".join([f\"{k}: {round(v,2)}\" for k,v in f.items()])\n",
        "    summary += f\"\\n\\nInformation DNA: {dna}\\n\\nAI Reasoning & Recommendations:\\n{reasoning}\"\n",
        "\n",
        "    return summary, g_map, g1, g2, g3, g4, pdf\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# GRADIO UI\n",
        "# ----------------------------------------------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üèô UrbanFlow AI v8\\n**Hackathon-Ready Smart City Simulator with AI Resource Recommendations**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        description = gr.Textbox(lines=4, label=\"Event Description / Idea\")\n",
        "        event_type = gr.Dropdown([\"Concert\",\"Football Match\",\"Market\",\"Festival\",\"General\"], label=\"Event Type\")\n",
        "        time_of_day = gr.Dropdown([\"Morning\",\"Afternoon\",\"Evening\",\"Night\"], label=\"Time of Day\")\n",
        "        weather = gr.Dropdown([\"Sunny\",\"Rainy\",\"Windy\"], label=\"Weather Condition\")\n",
        "\n",
        "    steps = gr.Slider(10,80,40,label=\"Simulation Steps\")\n",
        "\n",
        "    with gr.Row():\n",
        "        energy_limit = gr.Slider(10,200,50,label=\"Energy Limit\")\n",
        "        water_limit = gr.Slider(5,100,30,label=\"Water Limit\")\n",
        "        sanitation_limit = gr.Slider(5,100,20,label=\"Sanitation Limit\")\n",
        "\n",
        "    btn = gr.Button(\"üöÄ Run Simulation\")\n",
        "\n",
        "    out = gr.Textbox(lines=20,label=\"AI Intelligence Summary & Alerts\")\n",
        "    g_map = gr.Plot()\n",
        "    g1 = gr.Plot()\n",
        "    g2 = gr.Plot()\n",
        "    g3 = gr.Plot()\n",
        "    g4 = gr.Plot()\n",
        "    pdf = gr.File(label=\"üìÑ Download PDF Report\")\n",
        "\n",
        "    btn.click(\n",
        "        urbanflow_dashboard_v7,\n",
        "        inputs=[event_type, time_of_day, weather, steps, description, energy_limit, water_limit, sanitation_limit],\n",
        "        outputs=[out, g_map, g1, g2, g3, g4, pdf]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "w4zxQf0uN1e2",
        "outputId": "1e9ff187-8abe-497b-b5dd-516441c6d4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1770025812.py:200: DeprecationWarning:\n",
            "\n",
            "The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5da6484c1fca2afccb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5da6484c1fca2afccb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# UrbanFlow AI v8\n",
        "# Hackathon-Level Smart City Simulator with AI Resource Allocation\n",
        "# ==========================================================\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "import random, hashlib\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.pagesizes import A4\n",
        "import tempfile\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# CITY FLOW & RESOURCE SIMULATION\n",
        "# ----------------------------------------------------------\n",
        "def simulate_city_flow(event_type, time_of_day, weather, steps, energy_limit, water_limit, sanitation_limit):\n",
        "    base_people = {\"Concert\":3000,\"Football Match\":5000,\"Market\":1500,\"Festival\":4000,\"General\":1000}\n",
        "    base_vehicle = {\"Concert\":800,\"Football Match\":1200,\"Market\":400,\"Festival\":1000,\"General\":300}\n",
        "    base_energy = {\"Concert\":50,\"Football Match\":80,\"Market\":20,\"Festival\":60,\"General\":10}\n",
        "    base_water = {\"Concert\":30,\"Football Match\":50,\"Market\":10,\"Festival\":40,\"General\":5}\n",
        "    base_sanitation = {\"Concert\":20,\"Football Match\":30,\"Market\":10,\"Festival\":25,\"General\":5}\n",
        "\n",
        "    time_mod = {\"Morning\":0.8,\"Afternoon\":1.0,\"Evening\":1.2,\"Night\":0.6}\n",
        "    weather_mod = {\"Sunny\":1.0,\"Rainy\":0.7,\"Windy\":0.85}\n",
        "\n",
        "    people, traffic, energy, water, sanitation = [], [], [], [], []\n",
        "\n",
        "    for t in range(steps):\n",
        "        fluct = random.uniform(0.8,1.2)\n",
        "        p = base_people.get(event_type,1000) * time_mod.get(time_of_day,1.0) * weather_mod.get(weather,1.0) * fluct\n",
        "        v = base_vehicle.get(event_type,300) * time_mod.get(time_of_day,1.0) * weather_mod.get(weather,1.0) * fluct\n",
        "        e = min(base_energy.get(event_type,10) * fluct, energy_limit)\n",
        "        w = min(base_water.get(event_type,5) * fluct, water_limit)\n",
        "        s = min(base_sanitation.get(event_type,5) * fluct, sanitation_limit)\n",
        "        people.append(p)\n",
        "        traffic.append(v)\n",
        "        energy.append(e)\n",
        "        water.append(w)\n",
        "        sanitation.append(s)\n",
        "\n",
        "    return np.array(people), np.array(traffic), np.array(energy), np.array(water), np.array(sanitation)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# FEATURE EXTRACTION\n",
        "# ----------------------------------------------------------\n",
        "def extract_city_features(people, traffic, energy, water, sanitation):\n",
        "    f = {}\n",
        "    # Crowd Metrics\n",
        "    f[\"Avg Crowd\"] = np.mean(people)\n",
        "    f[\"Max Crowd\"] = np.max(people)\n",
        "    f[\"Min Crowd\"] = np.min(people)\n",
        "    f[\"Crowd Std\"] = np.std(people)\n",
        "    f[\"Crowd Variance\"] = np.var(people)\n",
        "    f[\"Peak Hour\"] = int(np.argmax(people))\n",
        "    f[\"Crowd Acceleration\"] = np.mean(np.diff(people))\n",
        "    f[\"Crowd Trend Volatility\"] = np.std(np.diff(people))\n",
        "    f[\"Crowd Revival Detected\"] = int(np.any(people[int(len(people)*0.6):] > np.mean(people[:int(len(people)*0.3)])))\n",
        "\n",
        "    # Traffic Metrics\n",
        "    f[\"Avg Traffic\"] = np.mean(traffic)\n",
        "    f[\"Max Traffic\"] = np.max(traffic)\n",
        "    f[\"Traffic Std\"] = np.std(traffic)\n",
        "    f[\"Traffic Variance\"] = np.var(traffic)\n",
        "    f[\"Traffic Peak\"] = int(np.argmax(traffic))\n",
        "    f[\"Traffic Trend Volatility\"] = np.std(np.diff(traffic))\n",
        "\n",
        "    # Resource Metrics\n",
        "    f[\"Avg Energy Usage\"] = np.mean(energy)\n",
        "    f[\"Max Energy Usage\"] = np.max(energy)\n",
        "    f[\"Avg Water Usage\"] = np.mean(water)\n",
        "    f[\"Max Water Usage\"] = np.max(water)\n",
        "    f[\"Avg Sanitation Load\"] = np.mean(sanitation)\n",
        "    f[\"Max Sanitation Load\"] = np.max(sanitation)\n",
        "\n",
        "    # Risk & Confidence\n",
        "    f[\"Resource Stress Alert\"] = int(np.max(people)/5000 > 0.7 or np.max(traffic)/1500 > 0.7)\n",
        "    f[\"Risk Level\"] = min(1.0, np.max(people)/5000 + np.max(traffic)/1500)\n",
        "    f[\"Longevity Score\"] = np.mean(people)/1000\n",
        "    f[\"Confidence Score\"] = max(0.1, 1 - f[\"Risk Level\"])\n",
        "    f[\"Event Pulse Score\"] = f[\"Longevity Score\"] * f[\"Confidence Score\"]\n",
        "\n",
        "    # Future Projection\n",
        "    f[\"Future Crowd T+30\"] = people[-1]*1.05\n",
        "    f[\"Future Traffic T+30\"] = traffic[-1]*1.05\n",
        "\n",
        "    # AI Resource Recommendation\n",
        "    f[\"Recommended Energy\"] = min(np.max(energy)*1.1, 200)\n",
        "    f[\"Recommended Water\"] = min(np.max(water)*1.1, 100)\n",
        "    f[\"Recommended Sanitation\"] = min(np.max(sanitation)*1.1, 100)\n",
        "\n",
        "    return f\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# INFORMATION DNA\n",
        "# ----------------------------------------------------------\n",
        "def information_dna(text):\n",
        "    return hashlib.sha256(text.encode()).hexdigest()[:16]\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# HUMAN-READABLE REASONING & ALERTS\n",
        "# ----------------------------------------------------------\n",
        "def reasoning_engine(f):\n",
        "    msg = []\n",
        "    msg.append(\"High risk of congestion!\" if f[\"Risk Level\"]>0.7 else \"Low congestion risk.\")\n",
        "    msg.append(\"Event is expected to be long-lasting.\" if f[\"Longevity Score\"]>2 else \"Event will fade quickly.\")\n",
        "    msg.append(\"Confidence to handle event is high.\" if f[\"Confidence Score\"]>0.7 else \"Need more planning.\")\n",
        "    msg.append(\"Trend revival detected!\" if f[\"Crowd Revival Detected\"] else \"No sudden revival detected.\")\n",
        "    msg.append(\"Resource stress alert!\" if f[\"Resource Stress Alert\"] else \"Resources sufficient.\")\n",
        "    msg.append(f\"AI Recommended Energy: {f['Recommended Energy']:.1f}\")\n",
        "    msg.append(f\"AI Recommended Water: {f['Recommended Water']:.1f}\")\n",
        "    msg.append(f\"AI Recommended Sanitation: {f['Recommended Sanitation']:.1f}\")\n",
        "    return \" \".join(msg)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# PDF REPORT\n",
        "# ----------------------------------------------------------\n",
        "def generate_pdf(features, reasoning, dna):\n",
        "    temp = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
        "    doc = SimpleDocTemplate(temp.name, pagesize=A4)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    story.append(Paragraph(\"<b>UrbanFlow AI v8 - Smart City AI Resource Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "    story.append(Paragraph(f\"Information DNA: <b>{dna}</b>\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    for k,v in features.items():\n",
        "        story.append(Paragraph(f\"{k}: {round(v,2)}\", styles[\"Normal\"]))\n",
        "\n",
        "    story.append(Spacer(1,12))\n",
        "    story.append(Paragraph(\"<b>AI Reasoning & Resource Recommendations</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Paragraph(reasoning, styles[\"Normal\"]))\n",
        "\n",
        "    doc.build(story)\n",
        "    return temp.name\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# DASHBOARD FUNCTION\n",
        "# ----------------------------------------------------------\n",
        "def urbanflow_dashboard_v8(event_type, time_of_day, weather, steps, description, energy_limit, water_limit, sanitation_limit):\n",
        "    people, traffic, energy, water, sanitation = simulate_city_flow(event_type, time_of_day, weather, steps, energy_limit, water_limit, sanitation_limit)\n",
        "    f = extract_city_features(people, traffic, energy, water, sanitation)\n",
        "    dna = information_dna(description)\n",
        "    reasoning = reasoning_engine(f)\n",
        "    pdf = generate_pdf(f, reasoning, dna)\n",
        "\n",
        "    # Animated City Grid\n",
        "    frames = []\n",
        "    for t in range(len(people)):\n",
        "        n_people = max(1,int(people[t]//100))\n",
        "        n_vehicle = max(1,int(traffic[t]//50))\n",
        "        x_people = np.random.rand(n_people)*10\n",
        "        y_people = np.random.rand(n_people)*10\n",
        "        x_vehicle = np.random.rand(n_vehicle)*10\n",
        "        y_vehicle = np.random.rand(n_vehicle)*10\n",
        "\n",
        "        scatter_people = go.Scatter(\n",
        "            x=x_people, y=y_people, mode='markers',\n",
        "            marker=dict(size=5, color='blue'),\n",
        "            name='People',\n",
        "            hovertemplate=f'Crowd: {people[t]:.0f}<br>Risk Level: {f[\"Risk Level\"]:.2f}<extra></extra>'\n",
        "        )\n",
        "        scatter_vehicle = go.Scatter(\n",
        "            x=x_vehicle, y=y_vehicle, mode='markers',\n",
        "            marker=dict(size=7, color='red' if f[\"Risk Level\"]>0.7 else 'green'),\n",
        "            name='Vehicles',\n",
        "            hovertemplate=f'Vehicles: {traffic[t]:.0f}<br>Risk Level: {f[\"Risk Level\"]:.2f}<extra></extra>'\n",
        "        )\n",
        "\n",
        "        frames.append(go.Frame(data=[scatter_people, scatter_vehicle], name=str(t)))\n",
        "\n",
        "    g_map = go.Figure(data=[frames[0].data[0], frames[0].data[1]], frames=frames)\n",
        "    g_map.update_layout(\n",
        "        title=\"üåÜ Smart City Animated Grid\",\n",
        "        updatemenus=[{\"type\":\"buttons\",\"buttons\":[{\"label\":\"Play\",\"method\":\"animate\",\"args\":[None]}]}],\n",
        "        xaxis=dict(range=[0,10]), yaxis=dict(range=[0,10])\n",
        "    )\n",
        "\n",
        "    # Line Charts\n",
        "    g1 = go.Figure(go.Scatter(y=people, mode=\"lines+markers\"))\n",
        "    g1.update_layout(title=\"üìà Crowd Flow Over Time\")\n",
        "    g2 = go.Figure(go.Scatter(y=traffic, mode=\"lines+markers\"))\n",
        "    g2.update_layout(title=\"üöó Traffic Flow Over Time\")\n",
        "    g3 = go.Figure(go.Heatmap(z=[people, traffic, energy], colorscale=\"Viridis\"))\n",
        "    g3.update_layout(title=\"üå° Heatmap: Crowd, Traffic, Energy\")\n",
        "    g4 = go.Figure(go.Scatterpolar(\n",
        "        r=[f[\"Avg Crowd\"], f[\"Max Crowd\"], f[\"Avg Traffic\"], f[\"Max Traffic\"], f[\"Risk Level\"]],\n",
        "        theta=[\"Avg Crowd\",\"Max Crowd\",\"Avg Traffic\",\"Max Traffic\",\"Risk\"],\n",
        "        fill=\"toself\"\n",
        "    ))\n",
        "    g4.update_layout(title=\"üï∏ Event Health Radar\")\n",
        "\n",
        "    summary = \"\\n\".join([f\"{k}: {round(v,2)}\" for k,v in f.items()])\n",
        "    summary += f\"\\n\\nInformation DNA: {dna}\\n\\nAI Reasoning & Recommendations:\\n{reasoning}\"\n",
        "\n",
        "    return summary, g_map, g1, g2, g3, g4, pdf\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# GRADIO UI\n",
        "# ----------------------------------------------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üèô UrbanFlow AI v8\\n**Hackathon-Ready Smart City Simulator with AI Resource Recommendations**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        description = gr.Textbox(lines=4, label=\"Event Description / Idea\")\n",
        "        event_type = gr.Dropdown([\"Concert\",\"Football Match\",\"Market\",\"Festival\",\"General\"], label=\"Event Type\")\n",
        "        time_of_day = gr.Dropdown([\"Morning\",\"Afternoon\",\"Evening\",\"Night\"], label=\"Time of Day\")\n",
        "        weather = gr.Dropdown([\"Sunny\",\"Rainy\",\"Windy\"], label=\"Weather Condition\")\n",
        "\n",
        "    steps = gr.Slider(10,80,40,label=\"Simulation Steps\")\n",
        "\n",
        "    with gr.Row():\n",
        "        energy_limit = gr.Slider(10,200,50,label=\"Energy Limit\")\n",
        "        water_limit = gr.Slider(5,100,30,label=\"Water Limit\")\n",
        "        sanitation_limit = gr.Slider(5,100,20,label=\"Sanitation Limit\")\n",
        "\n",
        "    btn = gr.Button(\"üöÄ Run Simulation\")\n",
        "\n",
        "    out = gr.Textbox(lines=25,label=\"AI Intelligence Summary & Alerts\")\n",
        "    g_map = gr.Plot()\n",
        "    g1 = gr.Plot()\n",
        "    g2 = gr.Plot()\n",
        "    g3 = gr.Plot()\n",
        "    g4 = gr.Plot()\n",
        "    pdf = gr.File(label=\"üìÑ Download PDF Report\")\n",
        "\n",
        "    btn.click(\n",
        "        urbanflow_dashboard_v8,\n",
        "        inputs=[event_type, time_of_day, weather, steps, description, energy_limit, water_limit, sanitation_limit],\n",
        "        outputs=[out, g_map, g1, g2, g3, g4, pdf]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "L2dS9L72RkDH",
        "outputId": "4e6343d2-7525-4cd6-a82e-2ea1ab3d34f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1192438805.py:204: DeprecationWarning:\n",
            "\n",
            "The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3d8cbadda83f44b92f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3d8cbadda83f44b92f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explanation Quality Scorer**\n",
        "Idea\n",
        "\n",
        "An answer can be correct but poorly explained.\n",
        "\n",
        "Your ML scores:\n",
        "\n",
        "Clarity\n",
        "\n",
        "Logical flow\n",
        "\n",
        "Knowledge gap jumps\n",
        "\n",
        "ML Logic\n",
        "\n",
        "Sentence complexity\n",
        "\n",
        "Concept dependency graphs\n",
        "\n",
        "Explanation entropy\n",
        "\n",
        "Output\n",
        "\n",
        "‚ÄúCorrect answer, poor explanation: 42/100‚Äù\n",
        "\n",
        "Very unique."
      ],
      "metadata": {
        "id": "aGI4NqJHA3uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio sentence-transformers nltk textstat numpy scikit-learn networkx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDjRWSjj2AFS",
        "outputId": "145b90dc-3dd5-44f5-b420-fc152fcd8779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.12-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.3.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading textstat-0.7.12-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m176.6/176.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.17.2 textstat-0.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# STABLE BACKEND\n",
        "# ===========================\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# ===========================\n",
        "# IMPORTS\n",
        "# ===========================\n",
        "import nltk, numpy as np, textstat, io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ===========================\n",
        "# SETUP\n",
        "# ===========================\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "# ===========================\n",
        "# FEATURE EXTRACTION (50 FEATURES ‚Äî UNCHANGED)\n",
        "# ===========================\n",
        "def extract_features(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text.lower())\n",
        "    words_clean = [w for w in words if w.isalpha()]\n",
        "    embeddings = model.encode(sentences) if sentences else []\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # A. CLARITY (10)\n",
        "    sent_lengths = [len(word_tokenize(s)) for s in sentences]\n",
        "    features[\"avg_sentence_length\"] = np.mean(sent_lengths) if sent_lengths else 0\n",
        "    features[\"sentence_length_variance\"] = np.var(sent_lengths) if sent_lengths else 0\n",
        "    features[\"readability\"] = textstat.flesch_reading_ease(text)\n",
        "    features[\"lexical_diversity\"] = len(set(words_clean)) / (len(words_clean)+1)\n",
        "    features[\"avg_word_length\"] = np.mean([len(w) for w in words_clean]) if words_clean else 0\n",
        "    features[\"stopword_ratio\"] = sum(1 for w in words_clean if w in STOPWORDS) / (len(words_clean)+1)\n",
        "    features[\"syllable_density\"] = textstat.syllable_count(text) / (len(words_clean)+1)\n",
        "    features[\"redundancy\"] = 1 - features[\"lexical_diversity\"]\n",
        "    features[\"complex_word_ratio\"] = textstat.difficult_words(text) / (len(words_clean)+1)\n",
        "    features[\"passive_penalty\"] = text.lower().count(\"was\") + text.lower().count(\"were\")\n",
        "\n",
        "    # B. LOGICAL FLOW (8)\n",
        "    if len(embeddings) > 1:\n",
        "        sims = [cosine_similarity([embeddings[i]], [embeddings[i+1]])[0][0]\n",
        "                for i in range(len(embeddings)-1)]\n",
        "        features[\"local_coherence\"] = np.mean(sims)\n",
        "        features[\"flow_variance\"] = np.var(sims)\n",
        "        features[\"min_flow\"] = np.min(sims)\n",
        "        features[\"flow_drops\"] = sum(1 for s in sims if s < 0.4)\n",
        "    else:\n",
        "        sims = []\n",
        "        features.update({\"local_coherence\":0,\"flow_variance\":0,\"min_flow\":0,\"flow_drops\":0})\n",
        "\n",
        "    centroid = np.mean(embeddings, axis=0) if len(embeddings) > 0 else np.zeros(384)\n",
        "    global_sims = [cosine_similarity([e],[centroid])[0][0] for e in embeddings] if len(embeddings) > 0 else [0]\n",
        "    features[\"global_coherence\"] = np.mean(global_sims)\n",
        "    features[\"topic_zigzag\"] = np.var(global_sims)\n",
        "    features[\"ordering_stability\"] = features[\"local_coherence\"]\n",
        "    features[\"discourse_consistency\"] = features[\"global_coherence\"]\n",
        "\n",
        "    # C. KNOWLEDGE GAP (8)\n",
        "    gaps = [(1-s) for s in global_sims]\n",
        "    features[\"avg_gap\"] = np.mean(gaps)\n",
        "    features[\"gap_variance\"] = np.var(gaps)\n",
        "    features[\"gap_spikes\"] = sum(1 for g in gaps if g > 0.6) / (len(sentences)+1) # Normalize by sentence count\n",
        "    features[\"early_jump\"] = gaps[0] if gaps else 0\n",
        "    features[\"late_overload\"] = gaps[-1] if gaps else 0\n",
        "    features[\"concept_leaps\"] = sum(1 for s in sims if s < 0.35) if sims else 0\n",
        "    features[\"bridge_missing\"] = features[\"concept_leaps\"] / (len(sentences)+1)\n",
        "    features[\"abstraction_jump\"] = features[\"gap_variance\"]\n",
        "\n",
        "    # D. ENTROPY & FOCUS (7)\n",
        "    distances = [np.linalg.norm(e-centroid) for e in embeddings] if len(embeddings) > 0 else [0]\n",
        "    features[\"entropy\"] = np.mean(distances)\n",
        "    features[\"entropy_variance\"] = np.var(distances)\n",
        "    features[\"focus_score\"] = 1/(1+features[\"entropy\"])\n",
        "    features[\"topic_scatter\"] = np.max(distances)\n",
        "    features[\"noise\"] = features[\"entropy_variance\"]\n",
        "    features[\"redundant_entropy\"] = features[\"redundancy\"] * features[\"entropy\"]\n",
        "    features[\"information_spread\"] = np.std(distances)\n",
        "\n",
        "    # E. STRUCTURE & PEDAGOGY (8)\n",
        "    features[\"intro_presence\"] = int(len(sentences)>0)\n",
        "    features[\"conclusion_presence\"] = int(len(sentences)>1)\n",
        "    features[\"example_density\"] = text.lower().count(\"example\") / (len(sentences)+1)\n",
        "    features[\"stepwise_markers\"] = sum(1 for s in sentences if any(k in s.lower() for k in [\"first\",\"then\",\"next\"]))\n",
        "    features[\"definition_before_use\"] = features[\"intro_presence\"]\n",
        "    features[\"reuse_quality\"] = features[\"lexical_diversity\"]\n",
        "    features[\"depth_balance\"] = 1 - features[\"sentence_length_variance\"]\n",
        "    features[\"pedagogical_order\"] = features[\"local_coherence\"]\n",
        "\n",
        "    # F. COGNITIVE LOAD (7)\n",
        "    features[\"idea_density\"] = len(sentences) / (len(words_clean)+1)\n",
        "    features[\"working_memory_load\"] = features[\"avg_sentence_length\"] * features[\"complex_word_ratio\"]\n",
        "    features[\"compression_ratio\"] = len(words_clean) / (len(sentences)+1)\n",
        "    features[\"complexity_slope\"] = features[\"gap_variance\"]\n",
        "    features[\"overload_risk\"] = features[\"gap_spikes\"]\n",
        "    features[\"mental_effort\"] = features[\"entropy\"] * features[\"complex_word_ratio\"]\n",
        "    features[\"cognitive_smoothness\"] = features[\"local_coherence\"]\n",
        "\n",
        "    return features\n",
        "\n",
        "# ===========================\n",
        "# NORMALIZATION (Removed - now handled heuristically in score_explanation)\n",
        "# ===========================\n",
        "def normalize_features(features):\n",
        "    # This function is no longer used as normalization is done heuristically\n",
        "    # within score_explanation for single inputs.\n",
        "    pass\n",
        "\n",
        "# ===========================\n",
        "# VISUALIZATIONS (SAVED)\n",
        "# ===========================\n",
        "def save_plots(norm_df, group_scores, prefix=\"explanation\"):\n",
        "    # Radar\n",
        "    labels = list(group_scores.keys())\n",
        "    values = list(group_scores.values()) + [list(group_scores.values())[0]]\n",
        "    angles = np.linspace(0, 2*np.pi, len(labels)+1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(polar=True))\n",
        "    ax.plot(angles, values)\n",
        "    ax.fill(angles, values, alpha=0.3)\n",
        "    ax.set_thetagrids(angles[:-1]*180/np.pi, labels)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.set_title(\"Explanation Quality Radar\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{prefix}_radar.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Heatmap\n",
        "    plt.figure(figsize=(14,3))\n",
        "    sns.heatmap(norm_df.loc[[\"normalized\"]], cmap=\"viridis\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(\"Normalized Feature Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{prefix}_heatmap.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Bar\n",
        "    norm_df.loc[\"normalized\"].sort_values().plot(kind=\"barh\", figsize=(6,8))\n",
        "    plt.title(\"Feature Contribution Distribution\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{prefix}_bar.png\")\n",
        "    plt.close()\n",
        "\n",
        "# ===========================\n",
        "# FINAL SCORING API\n",
        "# ===========================\n",
        "def score_explanation(text, save_prefix=\"explanation\"):\n",
        "    features = extract_features(text)\n",
        "\n",
        "    # Heuristic Normalization to [0, 1] for a single text\n",
        "    norm_feats = {}\n",
        "\n",
        "    # A. CLARITY (10 features)\n",
        "    norm_feats[\"avg_sentence_length\"] = np.clip(1 - (features[\"avg_sentence_length\"] / 25), 0, 1) # Optimal around 15-20, higher penalty for longer\n",
        "    norm_feats[\"sentence_length_variance\"] = np.clip(1 - (features[\"sentence_length_variance\"] / 30), 0, 1) # Lower variance is better\n",
        "    norm_feats[\"readability\"] = np.clip(features[\"readability\"] / 100, 0, 1) # Flesch score, higher is better, max around 100\n",
        "    norm_feats[\"lexical_diversity\"] = features[\"lexical_diversity\"] # Already 0-1\n",
        "    norm_feats[\"avg_word_length\"] = np.clip(1 - np.abs(features[\"avg_word_length\"] - 5.5) / 3, 0, 1) # Optimal around 5.5\n",
        "    norm_feats[\"stopword_ratio\"] = np.clip(1 - np.abs(features[\"stopword_ratio\"] - 0.4) / 0.4, 0, 1) # Optimal around 0.4\n",
        "    norm_feats[\"syllable_density\"] = np.clip(1 - (features[\"syllable_density\"] / 3.0), 0, 1) # Higher density = more complex, penalize\n",
        "    norm_feats[\"redundancy\"] = 1 - features[\"redundancy\"] # 1 - (1 - lexical_diversity) = lexical_diversity (higher is better)\n",
        "    norm_feats[\"complex_word_ratio\"] = np.clip(1 - (features[\"complex_word_ratio\"] / 0.5), 0, 1) # Higher complexity penalize\n",
        "    norm_feats[\"passive_penalty\"] = np.clip(1 - (features[\"passive_penalty\"] / 5), 0, 1) # Penalize passive voice count\n",
        "\n",
        "    # B. LOGICAL FLOW (8 features)\n",
        "    norm_feats[\"local_coherence\"] = features[\"local_coherence\"] # Already 0-1\n",
        "    norm_feats[\"flow_variance\"] = np.clip(1 - (features[\"flow_variance\"] / 0.1), 0, 1) # Lower variance is better\n",
        "    norm_feats[\"min_flow\"] = features[\"min_flow\"] # Already 0-1\n",
        "    norm_feats[\"flow_drops\"] = np.clip(1 - (features[\"flow_drops\"] / 5), 0, 1) # Penalize drops\n",
        "    norm_feats[\"global_coherence\"] = features[\"global_coherence\"] # Already 0-1\n",
        "    norm_feats[\"topic_zigzag\"] = np.clip(1 - (features[\"topic_zigzag\"] / 0.1), 0, 1) # Lower is better\n",
        "    norm_feats[\"ordering_stability\"] = features[\"ordering_stability\"] # Same as local_coherence\n",
        "    norm_feats[\"discourse_consistency\"] = features[\"discourse_consistency\"] # Same as global_coherence\n",
        "\n",
        "    # C. KNOWLEDGE GAP (8 features)\n",
        "    norm_feats[\"avg_gap\"] = np.clip(1 - (features[\"avg_gap\"] / 0.5), 0, 1) # Lower is better\n",
        "    norm_feats[\"gap_variance\"] = np.clip(1 - (features[\"gap_variance\"] / 0.1), 0, 1) # Lower is better\n",
        "    norm_feats[\"gap_spikes\"] = np.clip(1 - (features[\"gap_spikes\"] / 0.5), 0, 1) # Penalize spikes, max 0.5 (as it's count/sentence_count)\n",
        "    norm_feats[\"early_jump\"] = np.clip(1 - (features[\"early_jump\"] / 0.5), 0, 1) # Penalize jump\n",
        "    norm_feats[\"late_overload\"] = np.clip(1 - (features[\"late_overload\"] / 0.5), 0, 1) # Penalize overload\n",
        "    norm_feats[\"concept_leaps\"] = np.clip(1 - (features[\"concept_leaps\"] / 5), 0, 1) # Penalize leaps\n",
        "    norm_feats[\"bridge_missing\"] = np.clip(1 - (features[\"bridge_missing\"] / 0.5), 0, 1) # Penalize missing bridges\n",
        "    norm_feats[\"abstraction_jump\"] = np.clip(1 - (features[\"abstraction_jump\"] / 0.1), 0, 1) # Same as gap_variance\n",
        "\n",
        "    # D. ENTROPY & FOCUS (7 features)\n",
        "    norm_feats[\"entropy\"] = np.clip(1 - (features[\"entropy\"] / 1.0), 0, 1) # Lower is better\n",
        "    norm_feats[\"entropy_variance\"] = np.clip(1 - (features[\"entropy_variance\"] / 1.0), 0, 1) # Lower is better\n",
        "    norm_feats[\"focus_score\"] = features[\"focus_score\"] # Already 0-1 due to 1/(1+entropy)\n",
        "    norm_feats[\"topic_scatter\"] = np.clip(1 - (features[\"topic_scatter\"] / 1.0), 0, 1) # Lower is better\n",
        "    norm_feats[\"noise\"] = norm_feats[\"entropy_variance\"] # Same as entropy_variance\n",
        "    norm_feats[\"redundant_entropy\"] = np.clip(1 - (features[\"redundant_entropy\"] / 0.5), 0, 1) # Lower is better\n",
        "    norm_feats[\"information_spread\"] = np.clip(1 - (features[\"information_spread\"] / 1.0), 0, 1) # Lower is better\n",
        "\n",
        "    # E. STRUCTURE & PEDAGOGY (8 features)\n",
        "    norm_feats[\"intro_presence\"] = features[\"intro_presence\"] # Already 0 or 1\n",
        "    norm_feats[\"conclusion_presence\"] = features[\"conclusion_presence\"] # Already 0 or 1\n",
        "    norm_feats[\"example_density\"] = np.clip(features[\"example_density\"] * 2, 0, 1) # Higher is better, scale up to 0.5\n",
        "    norm_feats[\"stepwise_markers\"] = np.clip(features[\"stepwise_markers\"] / 3, 0, 1) # Higher is better, max 3\n",
        "    norm_feats[\"definition_before_use\"] = features[\"definition_before_use\"] # Same as intro_presence\n",
        "    norm_feats[\"reuse_quality\"] = features[\"reuse_quality\"] # Same as lexical_diversity\n",
        "    norm_feats[\"depth_balance\"] = np.clip(1 - (features[\"sentence_length_variance\"] / 30), 0, 1) # Use variance again, lower variance is better for balance\n",
        "    norm_feats[\"pedagogical_order\"] = features[\"pedagogical_order\"] # Same as local_coherence\n",
        "\n",
        "    # F. COGNITIVE LOAD (7 features)\n",
        "    norm_feats[\"idea_density\"] = np.clip(features[\"idea_density\"] * 5, 0, 1) # Optimal around 0.2\n",
        "    norm_feats[\"working_memory_load\"] = np.clip(1 - (features[\"working_memory_load\"] / 10), 0, 1) # Lower is better\n",
        "    norm_feats[\"compression_ratio\"] = np.clip(1 - np.abs(features[\"compression_ratio\"] - 8) / 5, 0, 1) # Optimal around 8\n",
        "    norm_feats[\"complexity_slope\"] = np.clip(1 - (features[\"complexity_slope\"] / 0.1), 0, 1) # Lower is better\n",
        "    norm_feats[\"overload_risk\"] = np.clip(1 - (features[\"overload_risk\"] / 5), 0, 1) # Lower is better\n",
        "    norm_feats[\"mental_effort\"] = np.clip(1 - (features[\"mental_effort\"] / 1.0), 0, 1) # Lower is better\n",
        "    norm_feats[\"cognitive_smoothness\"] = features[\"cognitive_smoothness\"] # Same as local_coherence\n",
        "\n",
        "    # Create DataFrame from raw and normalized features\n",
        "    df_raw = pd.DataFrame([features], index=[\"raw\"])\n",
        "    df_norm = pd.DataFrame([norm_feats], index=[\"normalized\"])\n",
        "    norm_df = pd.concat([df_raw, df_norm])\n",
        "\n",
        "    final_score = float(df_norm.loc[\"normalized\"].mean() * 100)\n",
        "\n",
        "    group_scores = {\n",
        "        \"Clarity\": df_norm.iloc[0, 0:10].mean(), # Use the new df_norm for calculation\n",
        "        \"Flow\": df_norm.iloc[0, 10:18].mean(),\n",
        "        \"Knowledge Gap\": df_norm.iloc[0, 18:26].mean(),\n",
        "        \"Entropy\": df_norm.iloc[0, 26:33].mean(),\n",
        "        \"Structure\": df_norm.iloc[0, 33:41].mean(),\n",
        "        \"Cognitive Load\": df_norm.iloc[0, 41:48].mean()\n",
        "    }\n",
        "\n",
        "    verdict = (\n",
        "        \"Correct answer, poor explanation\" if final_score < 50 else\n",
        "        \"Average explanation\" if final_score < 70 else\n",
        "        \"Clear, high-quality explanation\"\n",
        "    )\n",
        "\n",
        "    save_plots(norm_df, group_scores, prefix=save_prefix)\n",
        "\n",
        "    return {\n",
        "        \"final_score\": round(final_score, 2),\n",
        "        \"verdict\": verdict,\n",
        "        \"group_scores\": group_scores,\n",
        "        \"features\": norm_df\n",
        "    }\n",
        "\n",
        "# ===========================\n",
        "# INPUT & TESTING\n",
        "# ===========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üìå Enter your explanation text (multi-line supported). End with triple quotes.\")\n",
        "    text_input = input(\"Paste text here:\\n\")\n",
        "\n",
        "    # Run scorer\n",
        "    result = score_explanation(text_input, save_prefix=\"demo\")\n",
        "\n",
        "    print(\"\\n‚úÖ Final Score:\", result[\"final_score\"])\n",
        "    print(\"‚úÖ Verdict:\", result[\"verdict\"])\n",
        "    print(\"\\nüìä Group Scores:\")\n",
        "    for k, v in result[\"group_scores\"].items():\n",
        "        print(f\"{k}: {round(v,3)}\")\n",
        "\n",
        "    print(\"\\nüìå Feature table saved in 'features' variable (Pandas DataFrame)\")\n",
        "    print(result[\"features\"].head())\n",
        "\n",
        "    print(\"\\nüé® Plots saved as 'demo_radar.png', 'demo_heatmap.png', 'demo_bar.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e63d19b987d4a86b873d275beb240e8",
            "9ee6ecaae2dc4336af16a7c368018b3a",
            "5d63e5daa8c34c8eb74772e16dd093cd",
            "c5d0429c3a984839990a456441cc2132",
            "54d322f12f7b4b3f91b123a36e5bc9a7",
            "622ae706e4df43c6a4c976804fcc674c",
            "3563892f359c4a64b6927042d0d2da22",
            "8f22da30a46143f5bc37b7583cebf11f",
            "034d563a6d3b41858cbe780afa9d4332",
            "6b275f57a68b4ce39dac45e867850fc0",
            "9d71c246d7704f3d8a0ab7ffb41cee84"
          ]
        },
        "id": "vVa5saqW7VH1",
        "outputId": "99af647a-e9cc-4297-8be1-cd839042391e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e63d19b987d4a86b873d275beb240e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå Enter your explanation text (multi-line supported). End with triple quotes.\n",
            "Paste text here:\n",
            "\"\"\" Linear regression is a method used to find a straight line that best fits the data. First, we assume a linear relationship between variables. Then we calculate coefficients by minimizing the error. For example, predicting house price from area uses linear regression. Finally, the model is evaluated using error metrics. \"\"\"\n",
            "\n",
            "‚úÖ Final Score: 61.78\n",
            "‚úÖ Verdict: Average explanation\n",
            "\n",
            "üìä Group Scores:\n",
            "Clarity: 0.622\n",
            "Flow: 0.517\n",
            "Knowledge Gap: 0.536\n",
            "Entropy: 0.656\n",
            "Structure: 0.693\n",
            "Cognitive Load: 0.696\n",
            "\n",
            "üìå Feature table saved in 'features' variable (Pandas DataFrame)\n",
            "            avg_sentence_length  sentence_length_variance  readability  \\\n",
            "raw                      12.600                 15.040000     34.25300   \n",
            "normalized                0.496                  0.498667      0.34253   \n",
            "\n",
            "            lexical_diversity  avg_word_length  stopword_ratio  \\\n",
            "raw                      0.78         5.224490            0.34   \n",
            "normalized               0.78         0.908163            0.85   \n",
            "\n",
            "            syllable_density  redundancy  complex_word_ratio  passive_penalty  \\\n",
            "raw                     1.92        0.22                 0.4              0.0   \n",
            "normalized              0.36        0.78                 0.2              1.0   \n",
            "\n",
            "            ...  reuse_quality  depth_balance  pedagogical_order  \\\n",
            "raw         ...           0.78     -14.040000           0.265155   \n",
            "normalized  ...           0.78       0.498667           0.265155   \n",
            "\n",
            "            idea_density  working_memory_load  compression_ratio  \\\n",
            "raw                  0.1                5.040           8.166667   \n",
            "normalized           0.5                0.496           0.966667   \n",
            "\n",
            "            complexity_slope  overload_risk  mental_effort  \\\n",
            "raw                 0.006046            0.0       0.295513   \n",
            "normalized          0.939539            1.0       0.704487   \n",
            "\n",
            "            cognitive_smoothness  \n",
            "raw                     0.265155  \n",
            "normalized              0.265155  \n",
            "\n",
            "[2 rows x 48 columns]\n",
            "\n",
            "üé® Plots saved as 'demo_radar.png', 'demo_heatmap.png', 'demo_bar.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n",
        "# ===========================\n",
        "# STABLE BACKEND\n",
        "# ===========================\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# ===========================\n",
        "# IMPORTS\n",
        "# ===========================\n",
        "import nltk, numpy as np, textstat, io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.pagesizes import letter\n",
        "\n",
        "# ===========================\n",
        "# SETUP\n",
        "# ===========================\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "# ===========================\n",
        "# FEATURE EXTRACTION\n",
        "# ===========================\n",
        "def extract_features(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text.lower())\n",
        "    words_clean = [w for w in words if w.isalpha()]\n",
        "    embeddings = model.encode(sentences) if sentences else []\n",
        "\n",
        "    features = {}\n",
        "    # --- CLARITY ---\n",
        "    sent_lengths = [len(word_tokenize(s)) for s in sentences]\n",
        "    features[\"avg_sentence_length\"] = np.mean(sent_lengths) if sent_lengths else 0\n",
        "    features[\"sentence_length_variance\"] = np.var(sent_lengths) if sent_lengths else 0\n",
        "    features[\"readability\"] = textstat.flesch_reading_ease(text)\n",
        "    features[\"lexical_diversity\"] = len(set(words_clean)) / (len(words_clean)+1)\n",
        "    features[\"avg_word_length\"] = np.mean([len(w) for w in words_clean]) if words_clean else 0\n",
        "    features[\"stopword_ratio\"] = sum(1 for w in words_clean if w in STOPWORDS) / (len(words_clean)+1)\n",
        "    features[\"syllable_density\"] = textstat.syllable_count(text) / (len(words_clean)+1)\n",
        "    features[\"redundancy\"] = 1 - features[\"lexical_diversity\"]\n",
        "    features[\"complex_word_ratio\"] = textstat.difficult_words(text) / (len(words_clean)+1)\n",
        "    features[\"passive_penalty\"] = text.lower().count(\"was\") + text.lower().count(\"were\")\n",
        "\n",
        "    # --- LOGICAL FLOW ---\n",
        "    if len(embeddings) > 1:\n",
        "        sims = [cosine_similarity([embeddings[i]], [embeddings[i+1]])[0][0] for i in range(len(embeddings)-1)]\n",
        "        features[\"local_coherence\"] = np.mean(sims)\n",
        "        features[\"flow_variance\"] = np.var(sims)\n",
        "        features[\"min_flow\"] = np.min(sims)\n",
        "        features[\"flow_drops\"] = sum(1 for s in sims if s < 0.4)\n",
        "    else:\n",
        "        sims = []\n",
        "        features.update({\"local_coherence\":0,\"flow_variance\":0,\"min_flow\":0,\"flow_drops\":0})\n",
        "\n",
        "    centroid = np.mean(embeddings, axis=0) if len(embeddings) > 0 else np.zeros(384)\n",
        "    global_sims = [cosine_similarity([e],[centroid])[0][0] for e in embeddings] if len(embeddings) > 0 else [0]\n",
        "    features[\"global_coherence\"] = np.mean(global_sims)\n",
        "    features[\"topic_zigzag\"] = np.var(global_sims)\n",
        "    features[\"ordering_stability\"] = features[\"local_coherence\"]\n",
        "    features[\"discourse_consistency\"] = features[\"global_coherence\"]\n",
        "\n",
        "    # --- KNOWLEDGE GAP ---\n",
        "    gaps = [(1-s) for s in global_sims]\n",
        "    features[\"avg_gap\"] = np.mean(gaps)\n",
        "    features[\"gap_variance\"] = np.var(gaps)\n",
        "    features[\"gap_spikes\"] = sum(1 for g in gaps if g > 0.6) / (len(sentences)+1)\n",
        "    features[\"early_jump\"] = gaps[0] if gaps else 0\n",
        "    features[\"late_overload\"] = gaps[-1] if gaps else 0\n",
        "    features[\"concept_leaps\"] = sum(1 for s in sims if s < 0.35) if sims else 0\n",
        "    features[\"bridge_missing\"] = features[\"concept_leaps\"] / (len(sentences)+1)\n",
        "    features[\"abstraction_jump\"] = features[\"gap_variance\"]\n",
        "\n",
        "    # --- ENTROPY & FOCUS ---\n",
        "    distances = [np.linalg.norm(e-centroid) for e in embeddings] if len(embeddings) > 0 else [0]\n",
        "    features[\"entropy\"] = np.mean(distances)\n",
        "    features[\"entropy_variance\"] = np.var(distances)\n",
        "    features[\"focus_score\"] = 1/(1+features[\"entropy\"])\n",
        "    features[\"topic_scatter\"] = np.max(distances)\n",
        "    features[\"noise\"] = features[\"entropy_variance\"]\n",
        "    features[\"redundant_entropy\"] = features[\"redundancy\"] * features[\"entropy\"]\n",
        "    features[\"information_spread\"] = np.std(distances)\n",
        "\n",
        "    # --- STRUCTURE & PEDAGOGY ---\n",
        "    features[\"intro_presence\"] = int(len(sentences)>0)\n",
        "    features[\"conclusion_presence\"] = int(len(sentences)>1)\n",
        "    features[\"example_density\"] = text.lower().count(\"example\") / (len(sentences)+1)\n",
        "    features[\"stepwise_markers\"] = sum(1 for s in sentences if any(k in s.lower() for k in [\"first\",\"then\",\"next\"]))\n",
        "    features[\"definition_before_use\"] = features[\"intro_presence\"]\n",
        "    features[\"reuse_quality\"] = features[\"lexical_diversity\"]\n",
        "    features[\"depth_balance\"] = 1 - features[\"sentence_length_variance\"]\n",
        "    features[\"pedagogical_order\"] = features[\"local_coherence\"]\n",
        "\n",
        "    # --- COGNITIVE LOAD ---\n",
        "    features[\"idea_density\"] = len(sentences) / (len(words_clean)+1)\n",
        "    features[\"working_memory_load\"] = features[\"avg_sentence_length\"] * features[\"complex_word_ratio\"]\n",
        "    features[\"compression_ratio\"] = len(words_clean) / (len(sentences)+1)\n",
        "    features[\"complexity_slope\"] = features[\"gap_variance\"]\n",
        "    features[\"overload_risk\"] = features[\"gap_spikes\"]\n",
        "    features[\"mental_effort\"] = features[\"entropy\"] * features[\"complex_word_ratio\"]\n",
        "    features[\"cognitive_smoothness\"] = features[\"local_coherence\"]\n",
        "\n",
        "    return features\n",
        "\n",
        "# ===========================\n",
        "# PLOTS\n",
        "# ===========================\n",
        "def save_plots(norm_df, group_scores, prefix=\"report\"):\n",
        "    # Radar\n",
        "    labels = list(group_scores.keys())\n",
        "    values = list(group_scores.values()) + [list(group_scores.values())[0]]\n",
        "    angles = np.linspace(0, 2*np.pi, len(labels)+1)\n",
        "    fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(polar=True))\n",
        "    ax.plot(angles, values)\n",
        "    ax.fill(angles, values, alpha=0.3)\n",
        "    ax.set_thetagrids(angles[:-1]*180/np.pi, labels)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.set_title(\"Explanation Quality Radar\")\n",
        "    plt.tight_layout()\n",
        "    radar_path = f\"{prefix}_radar.png\"\n",
        "    plt.savefig(radar_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Heatmap\n",
        "    plt.figure(figsize=(14,3))\n",
        "    sns.heatmap(norm_df.loc[[\"normalized\"]], cmap=\"viridis\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(\"Normalized Feature Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    heatmap_path = f\"{prefix}_heatmap.png\"\n",
        "    plt.savefig(heatmap_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Bar\n",
        "    norm_df.loc[\"normalized\"].sort_values().plot(kind=\"barh\", figsize=(6,8))\n",
        "    plt.title(\"Feature Contribution Distribution\")\n",
        "    plt.tight_layout()\n",
        "    bar_path = f\"{prefix}_bar.png\"\n",
        "    plt.savefig(bar_path)\n",
        "    plt.close()\n",
        "\n",
        "    return radar_path, heatmap_path, bar_path\n",
        "\n",
        "# ===========================\n",
        "# PDF REPORT (No Plots)\n",
        "# ===========================\n",
        "def generate_pdf(text, norm_df, group_scores, final_score, verdict, pdf_path=\"report.pdf\"):\n",
        "    doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"üìå AI Explanation Quality Report\", styles['Title']))\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"üìù Original Explanation Text:\", styles['Heading2']))\n",
        "    elements.append(Paragraph(text.replace(\"\\n\",\"<br/>\"), styles['Normal']))\n",
        "    elements.append(Spacer(1,12))\n",
        "\n",
        "    elements.append(Paragraph(f\"üèÜ Final Score: {round(final_score,2)}\", styles['Heading2']))\n",
        "    elements.append(Paragraph(f\"‚úÖ Verdict: {verdict}\", styles['Normal']))\n",
        "    elements.append(Spacer(1,12))\n",
        "\n",
        "    elements.append(Paragraph(\"üìä Group Scores:\", styles['Heading2']))\n",
        "    data = [[k, round(v,3)] for k,v in group_scores.items()]\n",
        "    table = Table([[\"Group\",\"Score\"]] + data)\n",
        "    elements.append(table)\n",
        "    elements.append(Spacer(1,12))\n",
        "\n",
        "    elements.append(Paragraph(\"üî¨ Normalized Features:\", styles['Heading2']))\n",
        "    for k,v in norm_df.loc[\"normalized\"].items():\n",
        "        elements.append(Paragraph(f\"{k}: {round(v,3)}\", styles['Normal']))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return pdf_path\n",
        "\n",
        "# ===========================\n",
        "# SCORING FUNCTION\n",
        "# ===========================\n",
        "def score_explanation(text):\n",
        "    features = extract_features(text)\n",
        "\n",
        "    # Heuristic normalization\n",
        "    norm_feats = {k: np.clip(v, 0, 1) for k,v in features.items()}\n",
        "\n",
        "    df_raw = pd.DataFrame([features], index=[\"raw\"])\n",
        "    df_norm = pd.DataFrame([norm_feats], index=[\"normalized\"])\n",
        "    norm_df = pd.concat([df_raw, df_norm])\n",
        "\n",
        "    final_score = float(df_norm.loc[\"normalized\"].mean() * 100)\n",
        "    group_scores = {\n",
        "        \"Clarity\": df_norm.iloc[0, 0:10].mean(),\n",
        "        \"Flow\": df_norm.iloc[0, 10:18].mean(),\n",
        "        \"Knowledge Gap\": df_norm.iloc[0, 18:26].mean(),\n",
        "        \"Entropy\": df_norm.iloc[0, 26:33].mean(),\n",
        "        \"Structure\": df_norm.iloc[0, 33:41].mean(),\n",
        "        \"Cognitive Load\": df_norm.iloc[0, 41:48].mean()\n",
        "    }\n",
        "    verdict = (\n",
        "        \"Correct answer, poor explanation\" if final_score < 50 else\n",
        "        \"Average explanation\" if final_score < 70 else\n",
        "        \"Clear, high-quality explanation\"\n",
        "    )\n",
        "\n",
        "    plots = save_plots(df_norm, group_scores, prefix=\"gradio_report\")\n",
        "    pdf_path = generate_pdf(text, df_norm, group_scores, final_score, verdict, pdf_path=\"gradio_report.pdf\")\n",
        "\n",
        "    return df_norm, group_scores, final_score, verdict, plots, pdf_path\n",
        "\n",
        "# ===========================\n",
        "# GRADIO APP\n",
        "# ===========================\n",
        "def gradio_interface(text):\n",
        "    norm_df, group_scores, final_score, verdict, plots, pdf_path = score_explanation(text)\n",
        "    return (\n",
        "        f\"Final Score: {round(final_score,2)}\\nVerdict: {verdict}\",\n",
        "        group_scores,\n",
        "        norm_df.loc[\"normalized\"].to_dict(),\n",
        "        [plots[0], plots[1], plots[2]],\n",
        "        pdf_path\n",
        "    )\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Paste your explanation here...\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Final Result\"),\n",
        "        gr.JSON(label=\"Group Scores\"),\n",
        "        gr.JSON(label=\"Normalized Feature Values\"),\n",
        "        gr.Gallery(label=\"Plots\"),\n",
        "        gr.File(label=\"Download PDF Report\")\n",
        "    ],\n",
        "    title=\"AI Explanation Quality Scorer + Report\",\n",
        "    description=\"Paste any explanation text and get a detailed quality score with plots and downloadable PDF report (without plots in PDF).\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869,
          "referenced_widgets": [
            "40cb098e504045479f85f0cb3ab67115",
            "4c5eb5ca02384ab8b45c7d7d019b2ad8",
            "32d87e741e8e41ceb321ae2935fc8ae6",
            "53414d685b6e424faa76e565482f3e19",
            "be5b8ce39a7e4a47a4092d368053b358",
            "3af73973650145ec910b4fe79199c5ea",
            "aab15832f3d04519a327fea2a96dadc9",
            "f6730e9c94bc428196282ee89b13ffa5",
            "f89705385d98453b8fa440c7861a8767",
            "3f62284946084d6399dad8da6b7f7012",
            "06022b5dc47d40d99081358fc2bfe663"
          ]
        },
        "id": "08nfWDGZ_ALp",
        "outputId": "d1cf21b6-a23d-4547-8483-973ee34d5612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40cb098e504045479f85f0cb3ab67115"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://35e4d4c0a60a08f80b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://35e4d4c0a60a08f80b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}